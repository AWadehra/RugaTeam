With the ushered in the big data era, medical data analysis has discovered new techniques for diagnostic diseases [1]. When patients visit healthcare institutions, these institutions typically store medical records for tracking patients’ medical histories and clinical information. As patient data accumulates, it becomes a valuable resource for large-scale medical data analysis, as shown in Fig. 1. Medical data includes medical images, speech detailing patient symptoms, text data describing patient information, genetic information, and physiological signals [2].

Medical narratives represent the main form of communication within medicine [3]. Text data holds a crucial position in medical data analysis, encapsulating a wealth of clinical information, including patient histories, physician notes, discharge summaries, pathology reports, and radiology interpretations [3], [4]. This textual information reflects the patient’s symptoms and medical history while conveying the clinician’s diagnostic reasoning and treatment plans. By leveraging natural language processing methods, text data can provide a more comprehensive picture of patient health conditions and facilitate more accurate diagnoses and personalized treatments [2].

The ability to reliably process and interpret vast quantities of medical text is essential for successfully creating high-performance predictive models and data-driven treatment strategies (precision medicine) [5]. In recent years, research has also explored the use of natural language processing methods to process medical records, focusing on the general task of extracting information from unstructured text [6], [7], [8] and the diagnostic classification of patients [9], [10]. Despite its potential, medical text analysis still faces significant challenges. One of the major challenges is how to process poor quality text data, with issues such as misspellings, incomplete records, and inconsistent terminology, which further complicate the analysis [11]. There is also the challenge of ensuring data privacy and security, as sensitive patient information must be protected while enabling effective analysis [12]. Furthermore, achieving a balance between model complexity and interpretability is critical for clinical application. Clinicians need to understand how models arrive at conclusions to trust and utilize these conclusions in practice [13].

As significant progress has been made in medical data analysis, it is important for us to provide a comprehensive review of medical text analysis to reflect the methodological landscape and explore the role of medical text data in medical data analysis. Identifying the challenges in medical text analysis is a central focus of this review, with the goal of advancing the understanding of medical text analysis and its potential to enhance clinical decision-making.
Natural Language Processing (NLP) is a branch of artificial intelligence and linguistics that is focused on automatic analysis and representation of human (natural) language [14]. NLP approaches aim to learn knowledge of how human beings understand and use a natural language to enable computer systems to understand and manipulate natural languages to perform desired tasks [15]. Fig. 2 illustrates the historical evolution of NLP.

NLP began in the 1960s with the publication of ‘Introduction to Computational Linguistics’, which considered language from a symbolic perspective [16]. Some promising NLP systems were developed, including ELIZA (1964) and SHRDLU (1968). SHRDLU was a natural language understanding program that allowed user interaction in English [17]. ELIZA stimulated human–machine conversation using a pattern matching and substitution methodology [18].